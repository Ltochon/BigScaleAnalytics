{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PmkVT35O1nNa"
   },
   "source": [
    "# Personal Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The personal assignment, which is worth 30% of your final grade, consists of **three parts**:\n",
    "\n",
    "1. BigQuery\n",
    "2. Record linkage\n",
    "3. Elasticsearch\n",
    "\n",
    "**IMPORTANT**: In week 6, we will introduce ElasticSearch. Because your trial account will be limited to 14 days, we strongly advise you to start and finish Part 3 between weeks 6 and 7).\n",
    "\n",
    "This notebook already provides some of the code necessary to complete the assignment. Make sure to run those cells as you encounter them.\n",
    "\n",
    "In case of requested clarifications, we will update the notebook accordingly (so make sure to pull the assignment after we have notified you of such updates).\n",
    "\n",
    "Note that this assignment represents strictly *personal* work. Do not share it with your colleagues. Just do as much as you can on your own.\n",
    "\n",
    "**Grading**: For your work to be graded, you must:\n",
    "\n",
    "* Upload your completed notebook on [Moodle](https://moodle.unil.ch/mod/assign/view.php?id=1009190)\n",
    "* Answer all questions in this [Moodle quiz](https://moodle.unil.ch/mod/quiz/view.php?id=962087). The quiz is merely a way for the teaching team to facilitate the grading process. \n",
    "\n",
    "Your code will be compared to that your colleagues. In case of statistically high similarity, you will receive a grade of zero.\n",
    "\n",
    "**Deadline**: Please submit both your notebook and your quiz answers by **April 26, 23:59**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: SQL in BigQuery"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tpg4tcTjq1_6"
   },
   "source": [
    "In this first part, you will explore a public dataset from Google BigQuery. Similar to week 3, you will connect to BigQuery via Python. Your job is to write SQL queries to answer the questions below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connecting to BigQuery"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MB1ccWLwSmKu"
   },
   "source": [
    "To make things easier, we advise you to work in **Google Colab**. Some of you might prefer or need to use Jupyter for some reason. For example, people without a credit card to register on Google Cloud can use a colleague's service account key, in the form of JSON file (see this [documentation page](https://cloud.google.com/docs/authentication/getting-started#windows))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For Google Colab users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "emQhVqFdq2AC",
    "outputId": "0f2a6c30-ba68-4f61-953d-93f70eb71d49"
   },
   "outputs": [],
   "source": [
    "from google.colab import auth\n",
    "\n",
    "auth.authenticate_user()\n",
    "print(\"Authenticated\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For Jupyter users"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure to replace \"PATH_TO_CREDENTIALS_FILE\" with the *absolute* path to the JSON service account key, e.g., \"C:/Users/John/credentials.json\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install google-cloud-bigquery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"PATH_TO_CREDENTIALS_FILE\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Everyone"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure to replace \"YOUR-PROJECT-ID\" with the ID of one of your Google Cloud projects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VpHeNGKaq2AD"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from google.cloud import bigquery\n",
    "\n",
    "# Create a \"Client\" object\n",
    "client = bigquery.Client(project=\"YOUR-PROJECT-ID\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JTJpI9JLq2AE"
   },
   "source": [
    "### Words Dataset\n",
    "\n",
    "**Google Books** is a service that allows users to search the full text of scanned print materials like books and magazines, and displays a preview of the text surrounding the search terms (for works which are no longer copyrighted, the full text is available). This project was made possible thanks to a partnership between Google and multiple libraries, publishers and authors around the world.\n",
    "\n",
    "Related to that service is a tool called the **Ngram Viewer** (try it [here](https://books.google.com/ngrams)!), which can show how a word's usage evolved over time. The data that you will be using is the same data that powers this tool.\n",
    "\n",
    "**`words`** is a public dataset available in Google BigQuery and is therefore part of BigQuery's free tier. This means that each user receives 1 TB of free data processing every month, which can be used to run queries on any public dataset.\n",
    "\n",
    "The `words` dataset contains tables dedicated to different languages: English, French, German, Italian, Russian, etc. Each table contains all the distinct 1-gram found in Google Books for that language. As you can see in the schema below, a table contains each 1-gram's overall *term frequency* (i.e., how many times it occurs in the corpus) and *document frequency* (i.e., in how many documents it appears). These two metrics are aggregated from the detailed yearly data, which is also available in the table.\n",
    "\n",
    "For the assignment, we will only be using the **French** and **English (GB)** tables, which contain 3,273,887 and 3,725,801 1-grams respectively.\n",
    "\n",
    "Given the huge size of this dataset, performing a lot of queries can result in exceeding your free monthly quota. Therefore, you should try to avoid queries that have a big output. Always remember to use the LIMIT keyword (especially if you are not sure about the output of your query) to limit the size of the output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fmza3PkM1Q_9"
   },
   "source": [
    "The code below allows us to fetch and display the **schema** common to all tables in the `words` dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jMxl_O54q2AG",
    "outputId": "51c4d279-c8c9-4d61-e070-3032b0b1d263"
   },
   "outputs": [],
   "source": [
    "# Create a reference to the Words dataset\n",
    "words_ref = client.dataset(\"words\", project=\"bigquery-public-data\")\n",
    "\n",
    "# API request - fetch the dataset\n",
    "words_dataset = client.get_dataset(words_ref)\n",
    "\n",
    "# Create a reference to the \"fre_1gram\" table\n",
    "french_ref = words_ref.table(\"fre_1gram\")\n",
    "\n",
    "# Fetch the table (API request)\n",
    "french_table = client.get_table(french_ref)\n",
    "\n",
    "# Display schema\n",
    "french_table.schema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OdUmUmjL1jC4"
   },
   "source": [
    "### Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XpKjy7Vzq2AI"
   },
   "source": [
    "*According to this corpus, in which year was the oldest French document published?*\n",
    "\n",
    "**Hint #1**: To access the tables in your queries, use the following pattern: `FROM bigquery-public-data.[dataset].[table]`, where `[dataset]` = \"words\" and `[table]` = \"fre_1gram\" for French and \"eng_gb_1gram\" for English.\n",
    "\n",
    "**Hint #2**: As shown in the above schema, the `year` field is of type RECORD and therefore contains nested subfields. RECORD is a legacy SQL type which is similar in nature to the ARRAY type in standard SQL. Look up the [BigQuery documentation](https://cloud.google.com/bigquery/docs/reference/standard-sql/arrays) to learn how to flatten nested values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 78
    },
    "id": "h8m-cclAq2AJ",
    "outputId": "f3b73585-f3d2-46ce-a425-b22a723b41df"
   },
   "outputs": [],
   "source": [
    "q1 = \"\"\"\n",
    "YOUR QUERY HERE\n",
    "\"\"\"\n",
    "\n",
    "query_job_1 = client.query(q1)\n",
    "query_job_1.to_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zhkDL9OxzAqG"
   },
   "source": [
    "*What are the 20 French 1-grams with the highest term frequency over document frequency ratio?*\n",
    "\n",
    "**NB**: Consider only those that contain at least 3 characters (letters and punctuation alike)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 648
    },
    "id": "AfOj0VtGzBpl",
    "outputId": "64ea5d4c-4c27-426e-e842-bc95d4770250"
   },
   "outputs": [],
   "source": [
    "q2 = \"\"\"\n",
    "YOUR QUERY HERE\n",
    "\"\"\"\n",
    "\n",
    "query_job_2 = client.query(q2)\n",
    "query_job_2.to_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7kaIwEMpzCmZ"
   },
   "source": [
    "*How many French 1-grams appeared only once since the beginning of 1960?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 78
    },
    "id": "Ro-SX4yPzC7Y",
    "outputId": "c508f321-7c24-4bd4-937d-fad7e6322b44"
   },
   "outputs": [],
   "source": [
    "q3 = \"\"\"\n",
    "YOUR QUERY HERE\n",
    "\"\"\"\n",
    "\n",
    "query_job_3 = client.query(q3)\n",
    "query_job_3.to_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i95W1752zDWn"
   },
   "source": [
    "*Across English and French combined, for which year does Google Books have the highest number of words (not distinct words, but the overall quantity of published words)? Display the year and the sum of all the term frequencies.*\n",
    "\n",
    "**NB**: If a 1-gram exists in both English and French, make sure to include both term frequencies.\n",
    "\n",
    "**Hint**: For English, use the `eng_gb_1gram` table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 78
    },
    "id": "KERLP_pSOls8",
    "outputId": "c70b67af-5099-460f-ad16-4e200af368cf"
   },
   "outputs": [],
   "source": [
    "q4 = \"\"\"\n",
    "YOUR QUERY HERE\n",
    "\"\"\"\n",
    "\n",
    "query_job_4 = client.query(q4)\n",
    "query_job_4.to_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IE-fDaLGzB-U"
   },
   "source": [
    "*For the final and most challenging question, let's explore cognates... Of all French 1-grams, which ones are shared with English? Display the 30 shared 1-grams with the highest term frequency in English.*\n",
    "\n",
    "**NB**:\n",
    "\n",
    "1. Characters *with* diacritics (\"accents\") should not be considered as different than those *without* (i.e., é = ê = e for example).\n",
    "2. To make sure you get meaningful results, **consider only those where the difference between the term frequency in French and in English does not exceed 1,000,000**.\n",
    "\n",
    "**Hint**: To ignore diacritics, use the REGEXP_REPLACE function after having [NORMALIZE](https://cloud.google.com/bigquery/docs/reference/standard-sql/string_functions#normalize)'d the strings in NFD mode. The regular expression to match diacritics is `r\"\\pM\"`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 948
    },
    "id": "NCs8LY7BzCZL",
    "outputId": "5d728c53-fdb3-473d-a50b-c17c6227eced"
   },
   "outputs": [],
   "source": [
    "q5 = \"\"\"\n",
    "YOUR QUERY HERE\n",
    "\"\"\"\n",
    "\n",
    "query_job_5 = client.query(q5)\n",
    "query_job_5.to_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Record Linkage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this second part, you will attempt to find matches between two citation datasets using the `recordlinkage` Python module that we saw in week 5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Required modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install recordlinkage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import recordlinkage\n",
    "from recordlinkage.preprocessing import clean\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DBLP-ACM Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **DBLP** is an online bibliography of computer science articles from journals and proceedings. It was created in 1993 by the University of Trier in Germany.\n",
    "\n",
    "The Association for Computing Machinery (**ACM**) is one of the largest associations in the world of computer science. Their website provides a digital library containing all the articles and books that have been published by the ACM.\n",
    "\n",
    "In the Git folder for this assignment, you will find two CSV files which represent a (very) small fraction of these two databases. The DBLP file contains 2,616 records, and the ACM one 2,294 records.\n",
    "\n",
    "This dataset is publicly availabe at [this address](https://www.openicpsr.org/openicpsr/project/100843/version/V2/view) and has been used in several research projects on the topic of entity matching/record linkage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us load the two files and show a **preview**. As you can see, both tables use the same schema, which is convenient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dblp_url = \"https://raw.githubusercontent.com/michalis0/BigScaleAnalytics/master/assignment/data/DBLP2.csv\"\n",
    "dblp_full = pd.read_csv(dblp_url, dtype=\"str\", encoding=\"utf-8\")\n",
    "dblp_full.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acm_url = \"https://raw.githubusercontent.com/michalis0/BigScaleAnalytics/master/assignment/data/ACM.csv\"\n",
    "acm_full = pd.read_csv(acm_url, dtype=\"str\", encoding=\"utf-8\")\n",
    "acm_full.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let us **clean** the data a little bit. We are removing most of the punctuation and all diacritics. Also, the ACM data contains some HTML entities (&...;) that we want to revert back to their original character."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import html\n",
    "\n",
    "for df in [dblp_full, acm_full]:\n",
    "    for attr in [\"title\", \"authors\", \"venue\"]:\n",
    "        df[attr] = df[attr].apply(lambda x: html.unescape(str(x)))\n",
    "        df[attr] = clean(df[attr], lowercase=True, replace_by_none=\"[.,:]\", strip_accents=\"unicode\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because we want to keep computation times reasonable, we will work with a **sample** by keeping only works published in 1999 and 2000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dblp_full.rename(columns={\"id\": \"idDBLP\"}, inplace=True)\n",
    "acm_full.rename(columns={\"id\": \"idACM\"}, inplace=True)\n",
    "\n",
    "dblp = dblp_full[dblp_full[\"year\"].isin([\"1999\", \"2000\"])].set_index(\"idDBLP\").sort_index()\n",
    "acm = acm_full[acm_full[\"year\"].isin([\"1999\", \"2000\"])].set_index(\"idACM\").sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we load the **ground truth**, i.e., the actual matches between these two datasets. Note that this file contains 2224 matches. This implies that most ACM records have a match in the DBLP database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_url = \"https://raw.githubusercontent.com/michalis0/BigScaleAnalytics/master/assignment/data/DBLP-ACM_perfectMapping.csv\"\n",
    "G = pd.read_csv(G_url, dtype=\"str\")\n",
    "G.set_index(keys=[\"idDBLP\", \"idACM\"], inplace=True)\n",
    "G[\"match\"] = 1\n",
    "\n",
    "print(\"{} matches\".format(len(G)))\n",
    "G.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding candidates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*How many record pairs in total (aka candidates) can be compared between DBLP and ACM (i.e., between the samples that we created)?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In most real-world scenarios, it is impractical to check all candidates, as this task has quadratic complexity. To address this problem, rows are first grouped based on an attribute value that they share (e.g., same city, same ZIP code, etc.). This step of the record linkage process is known as \"blocking\".\n",
    "\n",
    "*Which blocking attribute results in the lowest (non-zero) number of candidates?*\n",
    "\n",
    "**Hint**: Be mindful that `recordlinkage` cares about order! E.g., if you choose DBLP to be \"left\" table and ACM your \"right\" table, make sure to use that scheme throughout the assignment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the case of citation data, the `year` attribute looks like the obvious choice for blocking, as it is likely to show the least amount of variance between the values of both datasets.\n",
    "\n",
    "However, it is not rare for dirty citation data to be off by 1 year. Using the `recordlinkage` module, we create an index of pairs with blocking on the year, but in such a way that the preceding year and the following year are put in the same block (e.g., 1999-2000-2001 constitute one block)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidates = recordlinkage.SortedNeighbourhoodIndex(on=\"year\", window=3).index(dblp, acm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding matches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now compare the two datasets. Since we are using the year as our blocking factor, the remaining attributes to compare are the title, authors, and the venue.\n",
    "\n",
    "If you explore the data, you will notice that, unlike ACM, DBLP uses the venue's abbreviation. Therefore, we don't want this attribute to weigh as much as the others in our comparison.\n",
    "\n",
    "*Create a `Compare` object called \"compare\" then add 3 comparison criteria for `title`, `authors` and `venue`.*\n",
    "\n",
    "**NB**: As the string comparison method, use the **Jaro-Winkler distance** with a threshold of 0.9, except for the venue where you will set the threshold at 0.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's compute the similarity between all the candidates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = compare.compute(candidates, dblp, acm)\n",
    "features.sum(axis=1).value_counts().sort_index(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we keep only record pairs above a certain threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_threshold = 1\n",
    "matches = features[features.sum(axis=1) > match_threshold]\n",
    "print(\"{} matches\".format(len(matches)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating our performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the precision and recall of our matching results with regards to the ground truth. Write them down somewhere for future reference.\n",
    "\n",
    "*Why is the recall so low?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 9 & 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far, we haven't taken `year` into account in our comparisons. Add to the `Compare` object an additional check for the year, which should be an exact match (by doing this, we are effectively nullifying the effect of the sorted neighborhood algorithm used earlier for blocking).\n",
    "\n",
    "*What is the observed impact on precision?*\n",
    "\n",
    "*What might be an unintended consequence of that?*\n",
    "\n",
    "**Hint**: Since we are adding a new comparison criterion, be sure to update the value of `match_threshold` accordingly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 11 & 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even without using a learning-based approach, we can already tell with reasonable accuracy whether two records are a match. However, it is always possible to improve our performance by adjusting how we compute similarity.\n",
    "\n",
    "In the case of citation data, it is not rare to find the right authors, but in a different order. Therefore, it is advisable to use a distance function that cares less about the order of words. Find such a function to replace Jaro-Winkler in the comparison of `authors`, and adapt the code in the \"Finding matches\" section.\n",
    "\n",
    "*Which distance function did you use?*\n",
    "\n",
    "*What is the observed behavior of precision?*\n",
    "\n",
    "**Hint**: Again, you may want to adjust the value of `match_threshold`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 13: Bonus!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Try to improve the recall while keeping precision above 90. What is the best score you can achieve?*\n",
    "\n",
    "**NB**: Many components of the matching pipeline will affect the recall, including cleaning and sampling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the code cell below, briefly explain your approach (2-3 sentences):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR APPROACH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Elasticsearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this final part, you will use Elasticsearch's JSON-based Query DSL in order to perform web log analysis.\n",
    "\n",
    "**NB**: In week 6, we will introduce ElasticSearch. Because your trial account will be limited to 14 days, we strongly advise you to start and finish Part 3 between weeks 6 and 7)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apache Access Log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of Elasticsearch's primary uses is to enable **log analysis**. In a real-world scenario, you would set up a live feed from the system of interest to the Elastic cloud. Here, for simplicity's sake, you will upload the log data as a file.\n",
    "\n",
    "The log you will be analyzing contains one day (March 29, 2020) of access information to **[laPlattform](https://laplattform.ch/)**, an educational platform for primary and secondary school. The website runs on Apache HTTP Server, so the file format is that of an Apache access log. It contains data such as the IP address of the client, the time of the request, the location of the requested resource, and information about the client's browser and device.\n",
    "\n",
    "In the log file, each line corresponds to a request. Here is an example of a request:\n",
    "\n",
    "`163.172.70.242 - \"\" [29/Mar/2020:06:54:33 +0200] \"GET /fr/login HTTP/1.1\" 200 76624 \"-\" \"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:58.0) Gecko/20100101 Firefox/58.0\"`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the Data to Elastic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should have already deployed an Elasticsearch service on the Elastic cloud during the lab (if you haven't, please refer to the lab recording of week 6).\n",
    "\n",
    "Once your deployment is ready, go to the **Kibana dashboard** and go through the following steps:\n",
    "\n",
    "1. Download the log file from the the course's [GitHub page](https://raw.githubusercontent.com/michalis0/BigScaleAnalytics/master/assignment/data/access.log) and unzip it.\n",
    "2. From the dashboard's side menu, go to *Analytics* > *Machine Learning* > *Data Visualizer*.\n",
    "3. Click on \"Upload file\" and upload the log file.\n",
    "4. Once the upload is complete, you must specify a so-called \"grok pattern\" so that Elastic can properly parse the file to create the fields to be indexed.\n",
    "  * Under *Summary*, click on \"Override settings\".\n",
    "  * In the `Grok pattern` field, copy/paste and apply the following pattern:\n",
    "  \n",
    "`%{IP:ipaddress} .*? .*? \\[%{HTTPDATE:timestamp}\\] \"%{WORD:verb} %{PATH:path}.*?\\/%{NUMBER:httpversion}\".*?%{NUMBER:status_code}.?*%{NUMBER:object_size}.?*%{QUOTEDSTRING:url}.*?%{QUOTEDSTRING:source}.*`\n",
    "5. Finally, click \"Import\" and specify an index name. Take note of the name you choose, as you will need it when writing queries. Also, make sure that the \"Create index pattern\" box is checked.\n",
    "\n",
    "Once that process is complete, the data will be indexed and available for query."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please note:\n",
    "\n",
    "* To run your queries, you must go to the **console** (from the side menu, *Management* > *Dev Tools*).\n",
    "* The queries must be written in Elasticsearch's **Query DSL** (Domain Specific Language). The full documentation (along with code samples) can be found [here](https://www.elastic.co/guide/en/elasticsearch/reference/current/query-dsl.html).\n",
    "* Once you have found the query to answer a particular question, **copy/paste** it in the notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 14"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*How many requests were sent from iPhone devices?*\n",
    "\n",
    "**NB**: The device information can be found in the `source` field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COPY/PASTE QUERY HERE\n",
    "\n",
    "# GET [YOUR-INDEX-NAME]/_search\n",
    "# {\n",
    "#   ...\n",
    "# }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*How many requests resulted in a client error (i.e., an HTTP response code from 400 to 499)?*\n",
    "\n",
    "**NB**: The response code can be found in the `status_code` field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COPY/PASTE QUERY HERE\n",
    "\n",
    "# GET [YOUR-INDEX-NAME]/_search\n",
    "# {\n",
    "#   ...\n",
    "# }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Which IP address made the most requests? How many requests were there from that IP address?*\n",
    "\n",
    "**NB**: The IP address can be found in the `ipaddress` field.\n",
    "\n",
    "**Hint**: You will need to perform an aggregation. To get the number of documents in an aggregation bucket, set the `size` parameter to 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COPY/PASTE QUERY HERE\n",
    "\n",
    "# GET [YOUR-INDEX-NAME]/_search\n",
    "# {\n",
    "#   ...\n",
    "# }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 17"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Which video file was requested the most from iPhone devices? How many requests were there for that file?*\n",
    "\n",
    "**NB #1**: On laPlattform, video files are stored in the MP4 format (.mp4).\n",
    "\n",
    "**NB #2**: The resource location can be found in the `path` field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COPY/PASTE QUERY HERE\n",
    "\n",
    "# GET [YOUR-INDEX-NAME]/_search\n",
    "# {\n",
    "#   ...\n",
    "# }\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "assignment_1_bigquery_solutions.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
