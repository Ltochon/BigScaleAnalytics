{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/michalis0/BigScaleAnalytics/blob/master/week11/Pytorch_regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fleet-potter"
   },
   "source": [
    "# Predicting house prices with neural networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "sunset-blast"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "likely-interaction"
   },
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ruled-spider"
   },
   "source": [
    "### loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 244
    },
    "id": "grave-snake",
    "outputId": "9b0b783a-75da-41d6-e23c-7e672dddb8a6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>...</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "0   1          60       RL         65.0     8450   Pave   NaN      Reg   \n",
       "1   2          20       RL         80.0     9600   Pave   NaN      Reg   \n",
       "2   3          60       RL         68.0    11250   Pave   NaN      IR1   \n",
       "3   4          70       RL         60.0     9550   Pave   NaN      IR1   \n",
       "4   5          60       RL         84.0    14260   Pave   NaN      IR1   \n",
       "\n",
       "  LandContour Utilities  ... PoolArea PoolQC Fence MiscFeature MiscVal MoSold  \\\n",
       "0         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
       "1         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      5   \n",
       "2         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      9   \n",
       "3         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
       "4         Lvl    AllPub  ...        0    NaN   NaN         NaN       0     12   \n",
       "\n",
       "  YrSold  SaleType  SaleCondition  SalePrice  \n",
       "0   2008        WD         Normal     208500  \n",
       "1   2007        WD         Normal     181500  \n",
       "2   2008        WD         Normal     223500  \n",
       "3   2006        WD        Abnorml     140000  \n",
       "4   2008        WD         Normal     250000  \n",
       "\n",
       "[5 rows x 81 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data = pd.read_csv(\"data/train.csv\")\n",
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "adjacent-substance",
    "outputId": "413e0514-ca9e-42db-cca1-93864ff41cbc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1460, 81)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "annual-officer"
   },
   "source": [
    "### Extracting the numeric columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "identified-wildlife",
    "outputId": "72d9ce41-c098-479c-d132-0d2a8a353055"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Id                 int64\n",
       "MSSubClass         int64\n",
       "MSZoning          object\n",
       "LotFrontage      float64\n",
       "LotArea            int64\n",
       "                  ...   \n",
       "MoSold             int64\n",
       "YrSold             int64\n",
       "SaleType          object\n",
       "SaleCondition     object\n",
       "SalePrice          int64\n",
       "Length: 81, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rubber-corrections",
    "outputId": "380b2002-c773-4853-b605-ca1a672eb0b2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Id', 'MSSubClass', 'LotFrontage', 'LotArea', 'OverallQual', 'OverallCond', 'YearBuilt', 'YearRemodAdd', 'MasVnrArea', 'BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', '1stFlrSF', '2ndFlrSF', 'LowQualFinSF', 'GrLivArea', 'BsmtFullBath', 'BsmtHalfBath', 'FullBath', 'HalfBath', 'BedroomAbvGr', 'KitchenAbvGr', 'TotRmsAbvGrd', 'Fireplaces', 'GarageYrBlt', 'GarageCars', 'GarageArea', 'WoodDeckSF', 'OpenPorchSF', 'EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'PoolArea', 'MiscVal', 'MoSold', 'YrSold', 'SalePrice'] \n",
      " 38\n"
     ]
    }
   ],
   "source": [
    "numeric_columns = list(raw_data.columns[(raw_data.dtypes==np.int64) |\n",
    "                 (raw_data.dtypes==np.float64)])\n",
    "print(numeric_columns, \"\\n\", len(numeric_columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "announced-incidence"
   },
   "source": [
    "Set `SalesPrice` as the last index, since it is the value we want to predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "intermediate-cable"
   },
   "outputs": [],
   "source": [
    "numeric_columns.remove('SalePrice')\n",
    "numeric_columns.append('SalePrice')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "extended-attribute"
   },
   "source": [
    "We do not need the `Id` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "marked-cancellation"
   },
   "outputs": [],
   "source": [
    "numeric_columns.remove('Id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "returning-vertex"
   },
   "source": [
    "Now we extract the numeric data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 215
    },
    "id": "irish-probe",
    "outputId": "c62a46ce-1641-4ff2-a661-e92904461cee"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>MasVnrArea</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>BsmtFinSF2</th>\n",
       "      <th>...</th>\n",
       "      <th>WoodDeckSF</th>\n",
       "      <th>OpenPorchSF</th>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2003</td>\n",
       "      <td>2003</td>\n",
       "      <td>196.0</td>\n",
       "      <td>706</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>1976</td>\n",
       "      <td>1976</td>\n",
       "      <td>0.0</td>\n",
       "      <td>978</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>298</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2001</td>\n",
       "      <td>2002</td>\n",
       "      <td>162.0</td>\n",
       "      <td>486</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>1915</td>\n",
       "      <td>1970</td>\n",
       "      <td>0.0</td>\n",
       "      <td>216</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>272</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "      <td>350.0</td>\n",
       "      <td>655</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>192</td>\n",
       "      <td>84</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   MSSubClass  LotFrontage  LotArea  OverallQual  OverallCond  YearBuilt  \\\n",
       "0          60         65.0     8450            7            5       2003   \n",
       "1          20         80.0     9600            6            8       1976   \n",
       "2          60         68.0    11250            7            5       2001   \n",
       "3          70         60.0     9550            7            5       1915   \n",
       "4          60         84.0    14260            8            5       2000   \n",
       "\n",
       "   YearRemodAdd  MasVnrArea  BsmtFinSF1  BsmtFinSF2  ...  WoodDeckSF  \\\n",
       "0          2003       196.0         706           0  ...           0   \n",
       "1          1976         0.0         978           0  ...         298   \n",
       "2          2002       162.0         486           0  ...           0   \n",
       "3          1970         0.0         216           0  ...           0   \n",
       "4          2000       350.0         655           0  ...         192   \n",
       "\n",
       "   OpenPorchSF  EnclosedPorch  3SsnPorch  ScreenPorch  PoolArea  MiscVal  \\\n",
       "0           61              0          0            0         0        0   \n",
       "1            0              0          0            0         0        0   \n",
       "2           42              0          0            0         0        0   \n",
       "3           35            272          0            0         0        0   \n",
       "4           84              0          0            0         0        0   \n",
       "\n",
       "   MoSold  YrSold  SalePrice  \n",
       "0       2    2008     208500  \n",
       "1       5    2007     181500  \n",
       "2       9    2008     223500  \n",
       "3       2    2006     140000  \n",
       "4      12    2008     250000  \n",
       "\n",
       "[5 rows x 37 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numeric_data = raw_data[numeric_columns]\n",
    "numeric_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "warming-cartoon"
   },
   "source": [
    "Now let's deal with the missing values in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "obvious-rider",
    "outputId": "5977a64c-7b76-49a5-b8d1-8cb7c35b0d5b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['LotFrontage', 'MasVnrArea', 'GarageYrBlt']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nan_columns = np.any(pd.isna(numeric_data), axis = 0)\n",
    "nan_columns = list(nan_columns[nan_columns == True].index)\n",
    "nan_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "activated-center"
   },
   "source": [
    "We simply replace them with zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "quarterly-murray",
    "outputId": "01d84027-c1e5-4cec-e3cb-84292eddb7a3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-032cc444f0e2>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  numeric_data['LotFrontage'] = numeric_data['LotFrontage'].fillna(0)\n",
      "<ipython-input-10-032cc444f0e2>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  numeric_data['MasVnrArea'] = numeric_data['MasVnrArea'].fillna(0)\n",
      "<ipython-input-10-032cc444f0e2>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  numeric_data['GarageYrBlt'] = numeric_data['GarageYrBlt'].fillna(0)\n"
     ]
    }
   ],
   "source": [
    "numeric_data['LotFrontage'] = numeric_data['LotFrontage'].fillna(0)\n",
    "numeric_data['MasVnrArea'] = numeric_data['MasVnrArea'].fillna(0)\n",
    "numeric_data['GarageYrBlt'] = numeric_data['GarageYrBlt'].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "joined-grade"
   },
   "source": [
    "let's split the data for training and test!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "northern-welsh"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "numeric_data_train, numeric_data_test = train_test_split(numeric_data, test_size=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "automatic-candy"
   },
   "source": [
    "### Normalizing the data\n",
    "Before training our linear regression model, we have to normalize the data. We do this by subtracting each column from its minimum value and then dividing it by the difference between maximum and minimum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "dominant-thanksgiving"
   },
   "outputs": [],
   "source": [
    "# saving max, min for each column\n",
    "maxs, mins = dict(), dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "pursuant-class"
   },
   "outputs": [],
   "source": [
    "for col in numeric_data:\n",
    "    maxs[col] = numeric_data_train[col].max()\n",
    "    mins[col] = numeric_data_train[col].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "resistant-bathroom"
   },
   "outputs": [],
   "source": [
    "numeric_data_train = (numeric_data_train - numeric_data_train.min()) / (numeric_data_train.max() - numeric_data_train.min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sensitive-notion"
   },
   "source": [
    "## Building a Linear Regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "insured-reviewer"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "perfect-promise"
   },
   "outputs": [],
   "source": [
    "numeric_x_columns = list(numeric_data_train.columns)\n",
    "numeric_x_columns.remove(\"SalePrice\")\n",
    "X_train_df = numeric_data_train[numeric_x_columns]\n",
    "y_train_df = pd.DataFrame(numeric_data_train[\"SalePrice\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wanted-surge"
   },
   "source": [
    "Now we have to convert the data into torch tensors. A `torch.Tensor` is a multi-dimensional matrix containing elements of a single data type. It's very similar to arrays in `NumPy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "ranging-hudson"
   },
   "outputs": [],
   "source": [
    "X_train = torch.tensor(X_train_df.values, dtype=torch.float)\n",
    "y_train = torch.tensor(y_train_df.values, dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "prescribed-reason",
    "outputId": "e5040a62-e5cf-4c7b-c792-08d07b1505b9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1314, 36]) torch.Size([1314, 1])\n"
     ]
    }
   ],
   "source": [
    "print(X_train.size(), y_train.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "baking-jamaica"
   },
   "source": [
    "### Defining a model with pytorch\n",
    "A model is always defined as a class in pytorch. It should have a `__init__` function in which you define the layers of your network. It also should have a `forward` function (method) that basically defines the forward pass on the network.\n",
    "\n",
    "For the beggining, let's start with a single layer network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "written-motel"
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, D_in, H1, D_out):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        self.linear1 = nn.Linear(D_in, H1)\n",
    "        self.linear2 = nn.Linear(H1, D_out)\n",
    "        self.activation = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        y_pred = self.activation(self.linear1(x))\n",
    "        y_pred = self.linear2(y_pred)\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "sustainable-blade"
   },
   "outputs": [],
   "source": [
    "D_in, D_out = X_train.shape[1], y_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "subjective-camcorder"
   },
   "outputs": [],
   "source": [
    "# defining the first model: an instance of the class \"Net\"\n",
    "model1 = Net(D_in, 500, D_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sticky-flash"
   },
   "source": [
    "The next steps is to define the __loss criterion__ and the __optimizer__ for the network. That is, we have to define the loss function we want to optimize during training and also the optimization method we are going to use, e.g, SGD, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "permanent-fancy"
   },
   "outputs": [],
   "source": [
    "# MSE loss\n",
    "criterion = nn.MSELoss(reduction='sum')\n",
    "# SGD optimizer for finding the weights of the network\n",
    "optimizer = torch.optim.SGD(model1.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "individual-gentleman"
   },
   "source": [
    "Now, we are ready to do the training. We can simply do this by a for loop over the number of iterations. The training has 3 main steps:\n",
    "- A forward pass to compute the prediction for the current data point (batch).\n",
    "- computing the loss for the current prediction.\n",
    "- A backward pass to compute the gradient of the loss with respect to the weight of the network.\n",
    "- Finaly, updating the weights of the network (`optimizer.step()`).\n",
    "\n",
    "Note that in each backward pass pytorch saves the gradient for all of the parameters. Therefore it is important to replace the old gradient values with zero in the beggining of each iteration, otherwise the gradients will be accumulated during the iterations!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JT_JOfiXhz6W",
    "outputId": "938b1b25-c6a8-4ce2-d717-38fdcb2852db"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-23-74e9974d4db1>:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  numeric_data_test[col] = (numeric_data_test[col] - mins[col]) / (maxs[col] - mins[col])\n"
     ]
    }
   ],
   "source": [
    "# we need to normalize the test data with the min and max value\n",
    "# from the training data\n",
    "for col in numeric_data_test.columns:\n",
    "    numeric_data_test[col] = (numeric_data_test[col] - mins[col]) / (maxs[col] - mins[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "ISuJYYwkgsbI"
   },
   "outputs": [],
   "source": [
    "# normalize the test data \n",
    "y_test_df = pd.DataFrame(numeric_data_test[\"SalePrice\"])\n",
    "y_test = torch.tensor(y_test_df.values, dtype=torch.float)\n",
    "x_test_df = numeric_data_test[numeric_x_columns]\n",
    "x_test = torch.tensor(x_test_df.values, dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "earlier-maximum",
    "outputId": "39b505c1-8fc1-4840-c6d0-5b7e93471de5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 34.5623664855957\n",
      "1 172.0092010498047\n",
      "2 1108.068359375\n",
      "3 6080.17138671875\n",
      "4 7131.15185546875\n",
      "5 19.550739288330078\n",
      "6 17.779253005981445\n",
      "7 16.810279846191406\n",
      "8 16.252552032470703\n",
      "9 15.906060218811035\n",
      "10 15.668546676635742\n",
      "11 15.487693786621094\n",
      "12 15.336785316467285\n",
      "13 15.201977729797363\n",
      "14 15.076241493225098\n",
      "15 14.955940246582031\n",
      "16 14.839076042175293\n",
      "17 14.724665641784668\n",
      "18 14.612165451049805\n",
      "19 14.501350402832031\n",
      "20 14.391997337341309\n",
      "21 14.283956527709961\n",
      "22 14.177154541015625\n",
      "23 14.071496963500977\n",
      "24 13.966920852661133\n",
      "25 13.863358497619629\n",
      "26 13.760807037353516\n",
      "27 13.65926742553711\n",
      "28 13.558708190917969\n",
      "29 13.459051132202148\n",
      "30 13.360267639160156\n",
      "31 13.262310981750488\n",
      "32 13.165193557739258\n",
      "33 13.06869125366211\n",
      "34 12.972902297973633\n",
      "35 12.877795219421387\n",
      "36 12.783416748046875\n",
      "37 12.689687728881836\n",
      "38 12.596590042114258\n",
      "39 12.504075050354004\n",
      "40 12.412138938903809\n",
      "41 12.320798873901367\n",
      "42 12.230049133300781\n",
      "43 12.139873504638672\n",
      "44 12.050202369689941\n",
      "45 11.960905075073242\n",
      "46 11.871986389160156\n",
      "47 11.783568382263184\n",
      "48 11.69563102722168\n",
      "49 11.608205795288086\n",
      "50 11.521332740783691\n",
      "51 11.434794425964355\n",
      "52 11.348675727844238\n",
      "53 11.26286506652832\n",
      "54 11.177398681640625\n",
      "55 11.092270851135254\n",
      "56 11.007448196411133\n",
      "57 10.923003196716309\n",
      "58 10.839022636413574\n",
      "59 10.755409240722656\n",
      "60 10.672298431396484\n",
      "61 10.589573860168457\n",
      "62 10.507071495056152\n",
      "63 10.424975395202637\n",
      "64 10.343231201171875\n",
      "65 10.261713027954102\n",
      "66 10.180657386779785\n",
      "67 10.100042343139648\n",
      "68 10.019939422607422\n",
      "69 9.94025993347168\n",
      "70 9.860952377319336\n",
      "71 9.781911849975586\n",
      "72 9.703371047973633\n",
      "73 9.625300407409668\n",
      "74 9.547658920288086\n",
      "75 9.470499992370605\n",
      "76 9.393765449523926\n",
      "77 9.317545890808105\n",
      "78 9.241888999938965\n",
      "79 9.166779518127441\n",
      "80 9.092220306396484\n",
      "81 9.018189430236816\n",
      "82 8.944741249084473\n",
      "83 8.87198257446289\n",
      "84 8.799893379211426\n",
      "85 8.728458404541016\n",
      "86 8.657581329345703\n",
      "87 8.58731460571289\n",
      "88 8.51767349243164\n",
      "89 8.448569297790527\n",
      "90 8.38005542755127\n",
      "91 8.312191009521484\n",
      "92 8.245063781738281\n",
      "93 8.1787109375\n",
      "94 8.113151550292969\n",
      "95 8.048307418823242\n",
      "96 7.984206199645996\n",
      "97 7.920860290527344\n",
      "98 7.8582444190979\n",
      "99 7.796347141265869\n",
      "100 7.735262393951416\n",
      "101 7.674964427947998\n",
      "102 7.615408420562744\n",
      "103 7.556509494781494\n",
      "104 7.4984025955200195\n",
      "105 7.441104888916016\n",
      "106 7.384551525115967\n",
      "107 7.32875919342041\n",
      "108 7.27360725402832\n",
      "109 7.21935510635376\n",
      "110 7.165929794311523\n",
      "111 7.113219261169434\n",
      "112 7.061314582824707\n",
      "113 7.0102715492248535\n",
      "114 6.960049629211426\n",
      "115 6.910569190979004\n",
      "116 6.861790657043457\n",
      "117 6.813844680786133\n",
      "118 6.766717910766602\n",
      "119 6.720394134521484\n",
      "120 6.674896240234375\n",
      "121 6.630138397216797\n",
      "122 6.586108207702637\n",
      "123 6.542810440063477\n",
      "124 6.5002923011779785\n",
      "125 6.4585676193237305\n",
      "126 6.417535305023193\n",
      "127 6.3771772384643555\n",
      "128 6.337551593780518\n",
      "129 6.29857063293457\n",
      "130 6.260267734527588\n",
      "131 6.222644805908203\n",
      "132 6.185692310333252\n",
      "133 6.149343490600586\n",
      "134 6.113583564758301\n",
      "135 6.078372955322266\n",
      "136 6.043677806854248\n",
      "137 6.009644508361816\n",
      "138 5.976233959197998\n",
      "139 5.943369388580322\n",
      "140 5.911088943481445\n",
      "141 5.879401206970215\n",
      "142 5.84823751449585\n",
      "143 5.81761360168457\n",
      "144 5.787524223327637\n",
      "145 5.7579803466796875\n",
      "146 5.728897571563721\n",
      "147 5.700272083282471\n",
      "148 5.672107696533203\n",
      "149 5.644413948059082\n",
      "150 5.617185592651367\n",
      "151 5.590426921844482\n",
      "152 5.564046382904053\n",
      "153 5.538151741027832\n",
      "154 5.512725830078125\n",
      "155 5.487729549407959\n",
      "156 5.463153839111328\n",
      "157 5.43899393081665\n",
      "158 5.415227890014648\n",
      "159 5.391852378845215\n",
      "160 5.368840217590332\n",
      "161 5.3462066650390625\n",
      "162 5.323916435241699\n",
      "163 5.3019561767578125\n",
      "164 5.280354976654053\n",
      "165 5.259100914001465\n",
      "166 5.238173007965088\n",
      "167 5.217486381530762\n",
      "168 5.197105407714844\n",
      "169 5.177041053771973\n",
      "170 5.157259941101074\n",
      "171 5.137775421142578\n",
      "172 5.118553161621094\n",
      "173 5.099608898162842\n",
      "174 5.0809102058410645\n",
      "175 5.062480449676514\n",
      "176 5.044286727905273\n",
      "177 5.02630090713501\n",
      "178 5.008557319641113\n",
      "179 4.991067886352539\n",
      "180 4.973746299743652\n",
      "181 4.956671237945557\n",
      "182 4.939822673797607\n",
      "183 4.923201084136963\n",
      "184 4.906846046447754\n",
      "185 4.890710353851318\n",
      "186 4.874785423278809\n",
      "187 4.859090805053711\n",
      "188 4.843608379364014\n",
      "189 4.828309535980225\n",
      "190 4.813178539276123\n",
      "191 4.7982306480407715\n",
      "192 4.783478260040283\n",
      "193 4.768936634063721\n",
      "194 4.7545671463012695\n",
      "195 4.7403388023376465\n",
      "196 4.726281642913818\n",
      "197 4.712368011474609\n",
      "198 4.698620796203613\n",
      "199 4.685051441192627\n",
      "200 4.671634197235107\n",
      "201 4.6583733558654785\n",
      "202 4.6452484130859375\n",
      "203 4.632264137268066\n",
      "204 4.61940860748291\n",
      "205 4.606681823730469\n",
      "206 4.594095706939697\n",
      "207 4.58168363571167\n",
      "208 4.569383144378662\n",
      "209 4.557182312011719\n",
      "210 4.545078277587891\n",
      "211 4.533056735992432\n",
      "212 4.521133899688721\n",
      "213 4.509327411651611\n",
      "214 4.497635841369629\n",
      "215 4.486049652099609\n",
      "216 4.47455358505249\n",
      "217 4.463177680969238\n",
      "218 4.451912879943848\n",
      "219 4.440762996673584\n",
      "220 4.429721355438232\n",
      "221 4.418801784515381\n",
      "222 4.407971382141113\n",
      "223 4.397259712219238\n",
      "224 4.3866424560546875\n",
      "225 4.376081466674805\n",
      "226 4.36561393737793\n",
      "227 4.3552470207214355\n",
      "228 4.344973087310791\n",
      "229 4.33477258682251\n",
      "230 4.324660778045654\n",
      "231 4.314647197723389\n",
      "232 4.30472993850708\n",
      "233 4.294890403747559\n",
      "234 4.28514289855957\n",
      "235 4.275485038757324\n",
      "236 4.265909194946289\n",
      "237 4.256425380706787\n",
      "238 4.247023582458496\n",
      "239 4.237702369689941\n",
      "240 4.2284674644470215\n",
      "241 4.219311237335205\n",
      "242 4.21023416519165\n",
      "243 4.201242446899414\n",
      "244 4.19233512878418\n",
      "245 4.183523654937744\n",
      "246 4.174786567687988\n",
      "247 4.166118621826172\n",
      "248 4.157524108886719\n",
      "249 4.1489973068237305\n",
      "250 4.140519618988037\n",
      "251 4.132100582122803\n",
      "252 4.123741626739502\n",
      "253 4.115439414978027\n",
      "254 4.107178211212158\n",
      "255 4.098973274230957\n",
      "256 4.090841770172119\n",
      "257 4.08277702331543\n",
      "258 4.07478141784668\n",
      "259 4.06685209274292\n",
      "260 4.058993816375732\n",
      "261 4.0511956214904785\n",
      "262 4.043452739715576\n",
      "263 4.0357770919799805\n",
      "264 4.028176307678223\n",
      "265 4.020656585693359\n",
      "266 4.013192176818848\n",
      "267 4.005804538726807\n",
      "268 3.9984750747680664\n",
      "269 3.9912078380584717\n",
      "270 3.9839954376220703\n",
      "271 3.976841449737549\n",
      "272 3.9697389602661133\n",
      "273 3.9626944065093994\n",
      "274 3.955706834793091\n",
      "275 3.9487738609313965\n",
      "276 3.941885232925415\n",
      "277 3.9350342750549316\n",
      "278 3.9282243251800537\n",
      "279 3.9214677810668945\n",
      "280 3.9147627353668213\n",
      "281 3.9081063270568848\n",
      "282 3.901492118835449\n",
      "283 3.894907236099243\n",
      "284 3.888350486755371\n",
      "285 3.88183331489563\n",
      "286 3.8753671646118164\n",
      "287 3.8689441680908203\n",
      "288 3.8625669479370117\n",
      "289 3.856233596801758\n",
      "290 3.8499412536621094\n",
      "291 3.843708038330078\n",
      "292 3.837519407272339\n",
      "293 3.8313674926757812\n",
      "294 3.825259208679199\n",
      "295 3.8192031383514404\n",
      "296 3.81318998336792\n",
      "297 3.8072221279144287\n",
      "298 3.8012983798980713\n",
      "299 3.795410394668579\n",
      "300 3.789559841156006\n",
      "301 3.783745527267456\n",
      "302 3.7779741287231445\n",
      "303 3.7722511291503906\n",
      "304 3.766573429107666\n",
      "305 3.7609381675720215\n",
      "306 3.7553274631500244\n",
      "307 3.74975848197937\n",
      "308 3.7442240715026855\n",
      "309 3.73872447013855\n",
      "310 3.7332563400268555\n",
      "311 3.7278218269348145\n",
      "312 3.7224228382110596\n",
      "313 3.7170605659484863\n",
      "314 3.711721420288086\n",
      "315 3.706413984298706\n",
      "316 3.701139211654663\n",
      "317 3.6958837509155273\n",
      "318 3.6906583309173584\n",
      "319 3.6854608058929443\n",
      "320 3.6803033351898193\n",
      "321 3.6751766204833984\n",
      "322 3.670074462890625\n",
      "323 3.6649973392486572\n",
      "324 3.6599433422088623\n",
      "325 3.654926300048828\n",
      "326 3.6499440670013428\n",
      "327 3.644993782043457\n",
      "328 3.640084743499756\n",
      "329 3.6352059841156006\n",
      "330 3.6303470134735107\n",
      "331 3.6255106925964355\n",
      "332 3.6207008361816406\n",
      "333 3.6159284114837646\n",
      "334 3.6111927032470703\n",
      "335 3.60648775100708\n",
      "336 3.6018142700195312\n",
      "337 3.597177267074585\n",
      "338 3.592581033706665\n",
      "339 3.5880069732666016\n",
      "340 3.5834460258483887\n",
      "341 3.578908681869507\n",
      "342 3.5743956565856934\n",
      "343 3.5699100494384766\n",
      "344 3.5654518604278564\n",
      "345 3.5610225200653076\n",
      "346 3.5566110610961914\n",
      "347 3.552222490310669\n",
      "348 3.547858476638794\n",
      "349 3.543515205383301\n",
      "350 3.5391879081726074\n",
      "351 3.534883737564087\n",
      "352 3.5306143760681152\n",
      "353 3.526365041732788\n",
      "354 3.5221333503723145\n",
      "355 3.5179250240325928\n",
      "356 3.513744592666626\n",
      "357 3.509587049484253\n",
      "358 3.5054540634155273\n",
      "359 3.501343011856079\n",
      "360 3.4972448348999023\n",
      "361 3.493150234222412\n",
      "362 3.4890637397766113\n",
      "363 3.4849939346313477\n",
      "364 3.4809420108795166\n",
      "365 3.476901054382324\n",
      "366 3.4728751182556152\n",
      "367 3.4688546657562256\n",
      "368 3.464848279953003\n",
      "369 3.4608540534973145\n",
      "370 3.456883668899536\n",
      "371 3.4529366493225098\n",
      "372 3.449005126953125\n",
      "373 3.445098876953125\n",
      "374 3.4412190914154053\n",
      "375 3.437364101409912\n",
      "376 3.433537483215332\n",
      "377 3.429737091064453\n",
      "378 3.425950765609741\n",
      "379 3.422182321548462\n",
      "380 3.418430805206299\n",
      "381 3.414689540863037\n",
      "382 3.410968542098999\n",
      "383 3.4072611331939697\n",
      "384 3.4035658836364746\n",
      "385 3.399895429611206\n",
      "386 3.396242141723633\n",
      "387 3.3926055431365967\n",
      "388 3.3889946937561035\n",
      "389 3.385390281677246\n",
      "390 3.38179087638855\n",
      "391 3.3782083988189697\n",
      "392 3.3746540546417236\n",
      "393 3.371126174926758\n",
      "394 3.367619514465332\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "395 3.3641397953033447\n",
      "396 3.3606760501861572\n",
      "397 3.357229232788086\n",
      "398 3.3537988662719727\n",
      "399 3.350385904312134\n",
      "400 3.346993923187256\n",
      "401 3.343614101409912\n",
      "402 3.340249538421631\n",
      "403 3.336897134780884\n",
      "404 3.3335561752319336\n",
      "405 3.3302245140075684\n",
      "406 3.3269050121307373\n",
      "407 3.3236029148101807\n",
      "408 3.320317029953003\n",
      "409 3.317049980163574\n",
      "410 3.31380033493042\n",
      "411 3.3105597496032715\n",
      "412 3.307331085205078\n",
      "413 3.3041152954101562\n",
      "414 3.3009142875671387\n",
      "415 3.2977304458618164\n",
      "416 3.2945685386657715\n",
      "417 3.2914175987243652\n",
      "418 3.288276195526123\n",
      "419 3.285147190093994\n",
      "420 3.2820518016815186\n",
      "421 3.2789783477783203\n",
      "422 3.2759130001068115\n",
      "423 3.2728641033172607\n",
      "424 3.269834280014038\n",
      "425 3.2668230533599854\n",
      "426 3.2638096809387207\n",
      "427 3.2608046531677246\n",
      "428 3.257805585861206\n",
      "429 3.2548203468322754\n",
      "430 3.2518506050109863\n",
      "431 3.248897075653076\n",
      "432 3.245960235595703\n",
      "433 3.2430379390716553\n",
      "434 3.240126609802246\n",
      "435 3.2372217178344727\n",
      "436 3.2343366146087646\n",
      "437 3.2314651012420654\n",
      "438 3.2285959720611572\n",
      "439 3.225738048553467\n",
      "440 3.222898244857788\n",
      "441 3.2200756072998047\n",
      "442 3.217258930206299\n",
      "443 3.214459180831909\n",
      "444 3.2116715908050537\n",
      "445 3.208899974822998\n",
      "446 3.2061386108398438\n",
      "447 3.203390121459961\n",
      "448 3.2006537914276123\n",
      "449 3.197927951812744\n",
      "450 3.1952130794525146\n",
      "451 3.1925065517425537\n",
      "452 3.189816474914551\n",
      "453 3.1871390342712402\n",
      "454 3.184471368789673\n",
      "455 3.1818132400512695\n",
      "456 3.179161787033081\n",
      "457 3.176520347595215\n",
      "458 3.173886775970459\n",
      "459 3.171262741088867\n",
      "460 3.1686453819274902\n",
      "461 3.166032075881958\n",
      "462 3.1634321212768555\n",
      "463 3.160845994949341\n",
      "464 3.1582634449005127\n",
      "465 3.155686378479004\n",
      "466 3.1531152725219727\n",
      "467 3.1505534648895264\n",
      "468 3.1480038166046143\n",
      "469 3.1454691886901855\n",
      "470 3.1429409980773926\n",
      "471 3.1404151916503906\n",
      "472 3.137899398803711\n",
      "473 3.1353859901428223\n",
      "474 3.1328773498535156\n",
      "475 3.130373477935791\n",
      "476 3.1278793811798096\n",
      "477 3.1253929138183594\n",
      "478 3.1229119300842285\n",
      "479 3.120436191558838\n",
      "480 3.117966651916504\n",
      "481 3.11549973487854\n",
      "482 3.1130433082580566\n",
      "483 3.110588312149048\n",
      "484 3.108139991760254\n",
      "485 3.105687379837036\n",
      "486 3.103241443634033\n",
      "487 3.1008036136627197\n",
      "488 3.0983736515045166\n",
      "489 3.095947027206421\n",
      "490 3.0935285091400146\n",
      "491 3.0911145210266113\n",
      "492 3.0887084007263184\n",
      "493 3.086313247680664\n",
      "494 3.083925485610962\n",
      "495 3.0815422534942627\n",
      "496 3.0791611671447754\n",
      "497 3.0767807960510254\n",
      "498 3.074418544769287\n",
      "499 3.0720653533935547\n"
     ]
    }
   ],
   "source": [
    "losses1 = []\n",
    "losses1_test = []\n",
    "for t in range(500):\n",
    "    y_pred = model1(X_train)\n",
    "    \n",
    "    loss = criterion(y_pred, y_train)\n",
    "    print(t, loss.item())\n",
    "    losses1.append(loss.item())\n",
    "    \n",
    "    if torch.isnan(loss):\n",
    "        break\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    # test loss\n",
    "    losses1_test.append(criterion(model1(x_test), y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "id": "KG4HrZFfhXZs",
    "outputId": "aecfffbe-2072-42c7-e1e3-303ab8e7ed49"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f9797c71d00>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(losses1, label=\"training loss\")\n",
    "plt.plot(losses1_test, label=\"test_loss\")\n",
    "plt.ylim(top=70, bottom=0.0)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "coordinated-mexican"
   },
   "source": [
    "Now let's try a new model with more neurons in the hidden layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "cathedral-exercise"
   },
   "outputs": [],
   "source": [
    "model2 = Net(D_in, 1000, D_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "exposed-league"
   },
   "outputs": [],
   "source": [
    "# MSE loss\n",
    "criterion = nn.MSELoss(reduction='sum')\n",
    "# SGD optimizer for finding the weights of the network\n",
    "optimizer = torch.optim.SGD(model2.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "operational-paper"
   },
   "outputs": [],
   "source": [
    "losses2 = []\n",
    "\n",
    "for t in range(500):\n",
    "    y_pred = model2(X_train)\n",
    "    \n",
    "    loss = criterion(y_pred, y_train)\n",
    "    # print(t, loss.item())\n",
    "    losses2.append(loss.item())\n",
    "    \n",
    "    if torch.isnan(loss):\n",
    "        break\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "id": "extra-consortium",
    "outputId": "5cb9b41e-9738-474d-f995-92b5a2e2e68b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f97c5c228b0>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAD8CAYAAABuHP8oAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAln0lEQVR4nO3deXgc1Z3u8e+vFy2WLduyJVtY3ggGvGIbsQViFscetgQmDBCGBHMhAzPJ3DuZ3LmJJ7mXhLm5GWYymZDM3Cd3/CSZeFgyQCBAIIDBhH21scGAMTIgG6+S5VXW1su5f1TJyHZLalkttarr/TxPPVV1urr7HPHw9vGpU1XmnENERIInku8KiIjIsVGAi4gElAJcRCSgFOAiIgGlABcRCSgFuIhIQPUa4GZ2kpmt7bLsN7Ovm1mFmT1pZnX+evRgVFhERDzWl3ngZhYFtgJnAF8DdjvnbjOzpcBo59y3BqaaIiJypL4OoSwEPnDObQIuA5b75cuBy3NYLxER6UWsj8d/Efi1vz3OObcdwDm33cyqMr3BzG4CbgIoKys79eSTT+5zJXc1t7N9XxszqstpPNDOruZ2Zk0Y6b24bS2MGAcjqvv8uSIiQbB69epdzrnKI8uzHkIxsyJgGzDTObfTzPY650Z1eX2Pc67HcfDa2lq3atWqvtUc+PcXP+LW373L2lsW8bNnP+BXL9az4fsXeS/eWgHnfB0W3tLnzxURCQIzW+2cqz2yvC9DKBcBbzjndvr7O82s2v/waqCh/9XMrMffGIv0coCISGHqS4BfwyfDJwAPA0v87SXAQ7mqVHcMy1Bo4NID/dUiIkNOVgFuZsOARcADXYpvAxaZWZ3/2m25r142DFAPXETCJ6uTmM65FmDMEWVNeLNSBlyP8awhFJFASCQSbNmyhba2tnxXZcgqKSmhpqaGeDye1fF9nYWSXxlGUDSEIhIMW7ZsYcSIEUyZMgWzTP8zh5tzjqamJrZs2cLUqVOzek/wL6W34DdBJAza2toYM2aMwrsbZsaYMWP69C+UQKRfz1Md1QMXCQqFd8/6+vcJRIB3ytg2M42Bi0goBSrAMzLNQhGRwTdlyhR27dqV9TE33HADVVVVzJo1K2d1CH6AawhFRALg+uuv5/HHH8/pZwYqwDOODmkIRUSyVF9fz8knn8xXvvIVZs2axbXXXstTTz3F2WefzbRp03jttdfYvXs3l19+OXPmzOHMM8/krbfeAqCpqYnFixczb948br755sPOzd15552cfvrpzJ07l5tvvplUKnXUdy9YsICKioqcticQ0wh7vZReQygigXLr797h3W37c/qZM44r57ufm9nrcRs3buS+++5j2bJlnHbaadx999288MILPPzww/zgBz9g4sSJzJs3jwcffJCnn36a6667jrVr13LrrbdyzjnncMstt/Doo4+ybNkyANavX88999zDiy++SDwe56tf/Sp33XUX1113XU7bl0kgArxT5jO0GkIRkexNnTqV2bNnAzBz5kwWLlyImTF79mzq6+vZtGkT999/PwAXXHABTU1N7Nu3j+eee44HHvAuRr/kkksYPdq7d9/KlStZvXo1p512GgCtra1UVWW8OWvOBSrAM9KVmCKBk01PeaAUFxcf2o5EIof2I5EIyWSSWOzoWOzsPGbqRDrnWLJkCX//938/QDXuXiDGwF1PQyS6ElNEcmjBggXcddddADzzzDOMHTuW8vLyw8ofe+wx9uzZA8DChQv5zW9+Q0ODd0PW3bt3s2nTpkGpayACvFPmKe6aRigiufO9732PVatWMWfOHJYuXcry5d6Dx7773e/y3HPPMX/+fFasWMGkSZMAmDFjBt///vdZvHgxc+bMYdGiRWzfvv2oz73mmms466yz2LBhAzU1NfziF7/od101hCIioTFlyhTefvvtQ/u/+tWvMr720ENH3x17zJgxrFix4tD+j3/840PbV199NVdfffVR76mvrz+0/etf//qo1/srED3wnmehaBqhiIRTIAK8U+bbBGgIRUTCKVABnpFFdBJTREIpEAHe8wMdNAtFRMIpEAHeKeMzMSNRBbiIhFKgAjwji0D66PsOiIgUukAEeM+zUNQDF5HB15fbyX788cecf/75TJ8+nZkzZ/KTn/wkJ3UI1DzwzLdCiYBTD1xEhq5YLMaPfvQj5s+fz4EDBzj11FNZtGgRM2bM6NfnBqMH3tNpzEhU88BFJCv5up1sdXU18+fPB2DEiBFMnz6drVu39rs9WfXAzWwU8HNgFt6kkBuADcA9wBSgHrjKOben3zXqKzONgYsEzWNLYce63H7m+Nlw0W29Hpbv28nW19ezZs0azjjjjH43OdshlJ8Ajzvn/sTMioBhwLeBlc6528xsKbAU+Fa/a9RXGgMXkT7I5+1km5ubueKKK7j99tspLy/vd1t6DXAzKwcWANcDOOc6gA4zuww4zz9sOfAMAxTgvT7QQWPgIsGSRU95oOTrdrKJRIIrrriCa6+9li984Qv9acIh2YyBHw80Av9uZmvM7OdmVgaMc85tB/DXGX9yzOwmM1tlZqsaGxv7VdnuT2KqBy4iuTEQt5N1znHjjTcyffp0vvGNb+SsrtkEeAyYD/zMOTcPOIg3XJIV59wy51ytc662srLyGKvZg0hUY+AikjMDcTvZF198kTvuuIOnn36auXPnMnfuXH7/+9/3u67ZjIFvAbY4517193+DF+A7zazaObfdzKqBhn7X5lioBy4iWcrX7WTPOeecw2at5EqvPXDn3A7gYzM7yS9aCLwLPAws8cuWAEe3OMcyXkpvmkYoIuGU7SyU/wrc5c9A+RD4L3jhf6+Z3QhsBq4cmCr2wgzSybx8tYhIPmUV4M65tUBthpcW5rQ23X9/9y9GopDqGIxqiEg/OecyzuQQT1+HWQJxJWanbmeh6CSmyJBXUlJCU1PTgIwFFwLnHE1NTZSUlGT9nkDcC0U3sxIJvpqaGrZs2UJ/pxMXspKSEmpqarI+PhAB3inzE9V0IY9IEMTjcaZOnZrvahSUQA2hZKQHOohISAUiwHt+pFoE0gpwEQmfQAR4p4xnr3Uhj4iEVKACPCONgYtISAUiwHuchaIxcBEJqUAEeKduZ6FoHriIhFCgAjwjzQMXkZAKRID3+ExMncQUkZAKRIB3yngpfUQBLiLhFKgAz0hj4CISUoEIcN0LRUTkaIEI8E7dX8ijHriIhE8gArzHS+k1D1xEQioQAd4j3QtFREKqAAJcPXARCadgBHhPZzHNNAYuIqEUjACnmzngoDFwEQmtwAR4tzQPXERCKhAB3vMDHdQDF5FwyuqZmGZWDxwAUkDSOVdrZhXAPcAUoB64yjm3Z2Cq2c2dCEHzwEUktPrSAz/fOTfXOVfr7y8FVjrnpgEr/f3BF4l66x4v1xQRKTz9GUK5DFjuby8HLu93bbrR86X0fhM0Di4iIZNtgDtghZmtNrOb/LJxzrntAP66KtMbzewmM1tlZqsaGxuPuaIZL6OHTwJc4+AiEjJZjYEDZzvntplZFfCkmb2X7Rc455YBywBqa2uPaZyj1/uBg8bBRSR0suqBO+e2+esG4LfA6cBOM6sG8NcNA1VJ6OEk5qExcPXARSRceg1wMyszsxGd28Bi4G3gYWCJf9gS4KGBqmTPFdQYuIiEUzZDKOOA3/pj0DHgbufc42b2OnCvmd0IbAauHKhK9no/cFAPXERCp9cAd859CJySobwJWDgQlcqk20vpdRJTREIqEFdi9khj4CISUoEI8J4vpfe75hoDF5GQCUSAA1h381A0Bi4iIRWYAO+W5oGLSEgFIsB7nIWiMXARCalABDjQ/ZU8mgcuIiEVnADvjsbARSSkAhHg2d0LRQEuIuESiACHnu6FogAXkXAKRoDrfuAiIkcJRoDT06X0GgMXkXAKTIB3S/PARSSkAhHgPV5Kr3ngIhJSgQhw6OlS+s4xcAW4iIRLYAK8WxoDF5GQCkSAu56upe88u6kxcBEJmUAEOPQwC6VzDFzTCEUkZAIT4N2K+A8VSifzWw8RkUEWiADv+W6EcW+dTgxKXUREhopABDj0cCl9tLMHriEUEQmXQAR4z/PA/QBPqQcuIuESiAAHsO7OYmoIRURCKusAN7Ooma0xs0f8/Qoze9LM6vz16IGrZg8iGkIRkXDqSw/8r4D1XfaXAiudc9OAlf7+gOjxJGZUQygiEk5ZBbiZ1QCXAD/vUnwZsNzfXg5cntOaHVmH7l44NISiaYQiEi7Z9sBvB74JdL1efZxzbjuAv67KbdWydGgIRT1wEQmXXgPczC4FGpxzq4/lC8zsJjNbZWarGhsbj+Ujen6kWtTvgafUAxeRcMmmB3428Hkzqwf+E7jAzO4EdppZNYC/bsj0ZufcMudcrXOutrKy8thr2uul9ApwEQmXXgPcOfe3zrka59wU4IvA0865LwEPA0v8w5YADw1YLXuiaYQiElL9mQd+G7DIzOqARf7+gOh5FopOYopIOMX6crBz7hngGX+7CViY+ypl1v0slM5phApwEQmXwFyJ2a1IFDANoYhI6AQ/wMHrhWsIRURCJjAB3u29UMAbB9eVmCISMoEI8B4fqQbeTBTdC0VEQiYQAQ49PFINvHFwjYGLSMgEJsB7pCEUEQmhQAR4LwMo/klMDaGISLgEIsChh3ng4Ae4euAiEi6BCfAeReOaRigioROIAO9tEgqRmMbARSR0AhHg0Ms88Ih64CISPoEJ8B5FogpwEQmdPt3MKl++ev6nuPbMSd0foGmEIhJCgQjw6pGlVI8s7f4ADaGISAhpCEVEJKAKI8A1hCIiIVQYAa7byYpICBVIgGsMXETCpzACPKoeuIiET2EEeCQOyfZ810JEZFAVRoDHSxTgIhI6hRHgsRJItuW7FiIig6rXADezEjN7zczeNLN3zOxWv7zCzJ40szp/PXrgq9sNBbiIhFA2PfB24ALn3CnAXOBCMzsTWAqsdM5NA1b6+/nRGeC93rZQRKRw9BrgztPs78b9xQGXAcv98uXA5QNRwazES8CldTGPiIRKVmPgZhY1s7VAA/Ckc+5VYJxzbjuAv64asFr2JlbirTWMIiIhklWAO+dSzrm5QA1wupnNyvYLzOwmM1tlZqsaGxuPsZq9OBTgmokiIuHRp1kozrm9wDPAhcBOM6sG8NcN3bxnmXOu1jlXW1lZ2b/adudQgLcOzOeLiAxB2cxCqTSzUf52KfBZ4D3gYWCJf9gS4KEBqmPv4v6tZtUDF5EQyeZ+4NXAcjOL4gX+vc65R8zsZeBeM7sR2AxcOYD17Fms2Fsn1AMXkfDoNcCdc28B8zKUNwELB6JSfaYxcBEJocK5EhM0Bi4ioVJgAa4euIiER2EEeNwPcI2Bi0iIFEaAqwcuIiFUYAGuHriIhEeBBbh64CISHoUR4IfGwFvyWw8RkUFUIAFeBhi0H8h3TUREBk1hBHgkAiXl0LY/3zURERk0hRHgAMUjoW1fvmshIjJoCifAS0ZCu3rgIhIehRXg6oGLSIgUUICXK8BFJFQKKMBH6iSmiIRK4QR4sXrgIhIuhRPgnScx0+l810REZFAUVoDjNBNFREKjcAJ8xHhvfWBHfushIjJICifAy4/z1vu35rceIiKDpAADfFt+6yEiMkgKJ8BHVHtrBbiIhEThBHisGMqqNIQiIqFROAEOMHoyNH2Q71qIiAyKXgPczCaa2R/MbL2ZvWNmf+WXV5jZk2ZW569HD3x1e1F9Cmx/U3PBRSQUsumBJ4H/7pybDpwJfM3MZgBLgZXOuWnASn8/v6pPgY4DsPvDfNdERGTA9Rrgzrntzrk3/O0DwHpgAnAZsNw/bDlw+QDVMXs1p3vrj57JazVERAZDn8bAzWwKMA94FRjnnNsOXsgDVd285yYzW2VmqxobG/tZ3V5UngRjT4K37hvY7xERGQKyDnAzGw7cD3zdOZf19erOuWXOuVrnXG1lZeWx1PEwZUUx2pNp2pOpTJWEU6+Hj1+B9Y/0+7tERIayrALczOJ44X2Xc+4Bv3inmVX7r1cDDQNTxcONH+k9gb5hf3vmA077CoyfDfd/BV79N0glBqNaIiKDLptZKAb8AljvnPvnLi89DCzxt5cAD+W+eker9gN8297WzAfEiuBLD8DkT8Nj34Qfz4KVfwc71oFzg1FFEZFBEcvimLOBLwPrzGytX/Zt4DbgXjO7EdgMXDkgNTxCZ4Dv2N/W/UHDq+BL90PdCnj9F/DCj+H5H8HoqTD9czD98zDhVO9p9iIiAdVrgDvnXgCsm5cX5rY6vRs/shSAbXt7CHDwxsNP/CNvaW6ADb+H9b+DV34GL/3Uu/R+2mI48UI4/lwoKhuE2ouI5E42PfAhZXhxjPKSGFv2tPThTVXeyc1Tr4fWvV7PfP3v4O0H4I3lEC2GqZ/xwnzaYu+KThGRIS5wAQ4wvbqcd7Yd44MbSkfBnKu8JdkBm1+C91fA+4/B7//GO6Zyut97vxBqToNoIP9MIlLgAplMc2pGsvzlTSRSaeLRfoxjx4rg+PO85cIfwK6NUPcEvP84vPyv8OLtUDIKpi3ywvyEz3o/ACIiQ0AgA3x2zSg6kh+xbus+5k/K4S1Yxp7gLWd9zXtA8gdPe73zuhWw7j6IxGDy2XDyJV6ga6hFRPIokAF+7rRKiqIRHn1re24DvKuSkTDzj70lnYItq7wToRse86YnPvZNGDcLTroYTroIqudqVouIDCpzgzg3ura21q1atSonn/XVu1bzfN0unvmb8xgzvDgnn5m1pg8+CfPNL4NLw4jjYOblMOsKb4qidTdxR0Skb8xstXOu9qjyoAZ43c4DXPST5/n0CWNZ9uVTKYlHc/K5fdayG95/wpvVsvFJSHXAqMlekM/+E6iaoTAXkX4puAAHuOf1zXzr/nXMnTiKf7lmHhMrhuXss49J615471F4+zfw4bPgUt4wy6nXw+wrdQJURI5JQQY4wONvb+e/3/smKef4xqITueHsqcT6MzMlV5ob4d0HYc0d3kMmYqXeePqpS2DiGeqVi0jWCjbAwbsvyi0PvcNT63dy0rgRfPuS6Zx7Yv/vfJgz29bA6uWw7jfeAyfGzYZP/yXM/II3lVFEpAcFHeAAzjmeeGcnP/j9ejbvbmHBiZV85+LpnDR+xIB83zFpb/aGV175GTS+5534PONmb4hFwysi0o2CD/BO7ckUd7y8iZ+urKO5PclVtRP5bwuncdyo0gH93j5Jp+GDlfDSv8BHz0LxSDjzL7xFQS4iRwhNgHfa29LBT1du5M5XNgFwzekT+dr5J1BVXjIo35+17W/Ccz/0ZrGUjISz/hLO+HMoKc93zURkiAhdgHfaureVf326jvtWbSEaMa47azJ/fu6nBn/ueG+2vwXP3AYbHoXS0XDut6D2Ro2Ri0h4A7zT5qYWfrKyjt+u2UJJPMqXz5zMjedMHXo98m1r4Klb4cM/QMXxsOjv4ORLNWtFJMRCH+CdNjY08y9P1/G7N7cRi0a48tQabl7wKSaNyfMc8q6cg41PwYr/6Z3snPRp+KPve1d4ikjoKMCPsKnpIP/v2Q+5f/UWUs7xuTnV/MV5JwytWSupJKz5D/jDD+BgI8z7Mnz2e1A2Nt81E5FBpADvxs79bfz8+Q+569XNtHSk+Oz0cfzZZ6Zy+tQKbKgMW7QfgGf/wZt+WFQGF/wvqL0BInm6fYCIDCoFeC/2HOxg+cv1LH+pnj0tCWZNKOfGc6ZyyezjKIoNgSs7ARreg8f+B3z0HIyfDRf/CCadke9aicgAU4BnqbUjxQNrtvDLFz7ig8aDjCsv5rqzpnDtGZMYNWwIzAhxzrtE/4nvwP6tcMqfwqJbvcfGiUhBUoD3UTrteLaukV++8BHP1+2iJB7hivk13HDOVD5VOTzf1fOu6nz+n+Clf4V4KZz/bTjtz/T4N5ECpADvh/d27OeXL3zEg2u30ZFMc95JlXz5zMmcd1IV0Uiex8l31XkPl/jgaaiaCRf/EKacnd86iUhOHXOAm9kvgUuBBufcLL+sArgHmALUA1c55/b0VomgBninXc3t3PnKJu5+dTMNB9qpGV3KtWdM5qramvxeGOScdyXnE9+GfR/D7Ktg8f+GEePzVycRyZn+BPgCoBn4jy4B/o/AbufcbWa2FBjtnPtWb5UIeoB3SqTSPPnuTu54eRMvf9hEUTTCpXOq+dJZk5k3cVT+Zq90tMDzP4KXfgrRYjhvqXezrGg8P/URkZzo1xCKmU0BHukS4BuA85xz282sGnjGOXdSb59TKAHeVd3OA9z5yibuf2Mrze1JZh5XzpfPnMznTjmOsuI8jUc3fQCPfct7QlDlyXDxP8HUz+SnLiLSb7kO8L3OuVFdXt/jnMv4dGEzuwm4CWDSpEmnbtq06ZgaMNQ1tyd5cM1W7nxlE+/tOEBZUZRL5xzHVadNZP6kPPTKnfOe2/n4Uti72XvE26K/g5E1g1sPEem3vAV4V4XYAz+Sc443Nu/hntc/5pG3ttPSkeKEquFcXTuRP54/gbGDPVaeaIUXbocXfuztn/nncM5fezfMEpFA0BBKHjS3J3n0rW3c8/rHvLF5L7GIsXB6FX9y6kTOPbFycC8Q2rsZnv4/8NY93m1rF/yNN+0wPsRu5iUiR8l1gP8QaOpyErPCOffN3j4nbAHeVd3OA9y76mMeeGMrTQc7GFka5+LZ4/n8KRM4fWrF4E1H3LEOnvyu90CJkRO9ID/lT3XbWpEhrD+zUH4NnAeMBXYC3wUeBO4FJgGbgSudc7t7q0SYA7xTIpXmhY27+N3abTzxzg4OdqQYV17M5+Ycx2VzJzBrQvngjJd/8AdYeat3+9ryGvjMX3s3y4oNsfuki4gu5BmKWjtSrHxvJw+t3cYzGxpIpBwTRpWyeOY4Fs8Yz2lTRhOLDuAwi3OwcaV3o6wtr8GIajjra16Q69FuIkOGAnyI29eS4Il3drDi3R08V7eLjmSaUcPiLDx5HItnjuOcE8YO3LRE57xncz77Q9j0AsSHwSnXeI92qzxxYL5TRLKmAA+Qg+1Jnq9rZMU7O3lq/U72tyWJR435k0az4MRKPjNtLLOOG0lkIMbNt78Jr/4brLsPUh1w/Hkw90tw8iVQNIQeeiESIgrwgEqk0rxev5vn63bx3PuNvLNtPwCjh8U5+4SxnHn8GE6bUsG0quG5DfTmRlj97/DGHbBvMxSXw8w/9uaTTz5bN80SGUQK8AKxq7mdFzfu4rn3d/F8XSMNB9oBKC+JUTulgtopozltSgWzjhtJaVEOHviQTnvDKmvvhncfgkSLN4f8xItg+qVw/PnqmYsMMAV4AXLOsXl3C6vq97Bq025er9/DxoZmAKIR44TK4cycUM7sCSOZNWEkM6rL+zeO3nHQO+n53qPw/mPQtg+iRVBzOhx/Lkxd4D23U/deEckpBXhI7D7YwepNe1i3ZS9vb9vPuq37aPR76WYwuWIYJ1SNYNq44Zw4bjjTqkbwqcrhfe+tpxJQ/4I3n/yj52D7W4CDWClUnwIT5sNx8711xfHel4vIMVGAh1jD/jbWbd3Huq37qNvZzPs7D/DRroMk095/ezOoGV3KlDFlTKwYxuSKYUyqGMakMd56REkWPeqW3V6gb3oJtr3hBXqy1XutaIQ3m2Wsv1SeBGNPglETNe9cJAsKcDlMIpVmU9NB6nY2U9fgLZubDrJ5dwt7WhKHHVtRVsTE0aVUjyxl/MgSbyk/fF0SP6IHn0pC43rY+oZ39eeuDdD4PjTv6HKQwfBxXpCPnPjJesR4KKuCsrHeo+KKhqsHL6GmAJes7WtN8PHuFj7e3cKm3S1s9re372tj5742DrQnj3rPqGFxxpeXUDmimDFlRVSUFTNmeBFjhxcx5tB2MWNibQzb/yE0bvDuz7JvizfLZe/H3jM+Ux1HVyhWCmWVMLwSho3x7uVSMspfd1lK/bLicigq85b4MIjk4GSuSB51F+CaCyZHGVkaZ6R/4jOT5vYkO/a1ecv+Nnbsa/XXbexq7qC+6SBNzR20dKQyvr80HqWirJpRwyZ531UaZ9TEOOUlUaqj+6myfYxhH6PcPspTuxmW2E1pxx7irbuw5p3eY+Ta9nmLy/wdh4mV+GHuh3rRMC/Yi4Z7251BHyv2jo0Vez8ah+2XeDf+ipX0fEw0rn8tyKBRgEufDS+OcULVcE6o6vnhzq0dKZoOttPU3EHTwXZ2NXfQ1NzBbr9sb2uCfa0J6hqa2duSYH9rgo5UuvNb/GXCoc8zg+FFMYaXxCgrjjG8LMrYogSV8TbGxFqpiLYyyloZaQcpi3RQZu0Mo40S5y1F6Tbi6RZiyVaiyVZs/xbvKUYdB73b7ibbINXevz+ORfwgL/KWWLEX6tGiLusjly7lsQxl0bj3hKVM5Yd9vl8WifvrmLd0lkVi3vz9Q9v6sQk6BbgMmNKiKDVFw6gZnd08ceccbYk0+/xg77rsbelgf2uC/W1JDrYnafaXpnZjU3OEg+1FHGgv42B7knSWo4JFsQjDiqKUxqOUFkUpLYtSFjeGxx3lsRTlsSTDYylGRFOURZMMiyQpiyQYFklQGklSYglKLEGRS1Dk2om7DmIuQdy1E013EHNJoi6BpRNYqgOSHd4QUaoDku3QfsCbzZNq98sTn7yeSnjHZPMvjP6waJeQ77KOxP2w77p95DHZvi/WzY9KzBve6iyzqL+fqazLsdmWRWLeD+pRxw3ibZwHmAJchgwz84K0KMr4kcd2n3LnHK2JlBfwbUkOtqc40J7gYHuK5vYEzW1JWhMpWjpStCZStHZ4S0siRVuHV97UnmLrAUdLIkJrB7R2OFoSUZyLAn2fNRMxKI5FKYlHKI5FKY5HKI7527EIxSVdtmOHH1MShZJommJLUWxJSiIpii1FkSUpIkmxJSkiRdySxElSRIIYKeKkiFmaOCmiJImRIkqKmEsSIUUkncTSSUgnIJ30Tjof2j5ifdh2wjs22db9+zJ+RqL3P9SgsU8CvvMHw6K9lEWO+FHJVJbpxyfyyfGn/xlUTc9pSxTgUlDMjGFFMYYVxagakbvPdc7RnkzTdmT4J1J0JNO0J1O0J9KHjmk/oqw96Zclumx3OWZfayLjsW3JFNnNMzAg7i9ZHG0Qj0YoikaIR414NOLtx7z9oliEWCRCLGLEouZtd67jnWVGLHrEMUeUxaMRohEjZhC3NPGIo8hSxM37IYqaI27O+9GJpImbI0qKuKWJ+uUxSxPF+zGKkCZmaSKkibqU92Pk0v76kwWXgnTK//HosnZ9LessP7Is7f2LyrUeXta5fej7u9RlxmUKcJF8MDNK4lFK4lFGDfKdA1JpRyKVpiOVJpFMk0h12U+lSSQdHak0HUl/3186Us4/vsv+oc/osu+/1/s87z0dqTTJtCPpr1s6kv6+I5lOf7LdeVyXYzuPyXYo69hE/OXoHywziJoRjRyxZFvml0ci3o/UUcdGjUjcfy3D+yN2xPv8ssvLJzA1x38FBbjIEOeFQPToufZDXLoz2DMFfpcfgkQq7f9IOVJdfwjS6UNlncckU45E2ts+bHGOVMpbd35v17LO49LO+4yuZYe9dkRZRzJ9+Gd2+b7OskPrLu8/ssw5mDdpFFPHluX0b6wAF5EBEYkYRRGjiMI5aXis0mk3IBN+FOAiIgNsQO7dD/ppFBEJKgW4iEhAKcBFRAJKAS4iElD9CnAzu9DMNpjZRjNbmqtKiYhI7445wM0sCvxf4CJgBnCNmc3IVcVERKRn/emBnw5sdM596JzrAP4TuCw31RIRkd70Zx74BODjLvtbgDOOPMjMbgJu8nebzWzDMX7fWGDXMb43qNTmcFCbw6E/bZ6cqbA/AZ5pZvpRdz9wzi0DlvXje7wvM1uV6YkUhUxtDge1ORwGos39GULZAkzssl8DbOtfdUREJFv9CfDXgWlmNtXMioAvAg/nploiItKbYx5Ccc4lzewvgSeAKPBL59w7OavZ0fo9DBNAanM4qM3hkPM2D+pT6UVEJHd0JaaISEApwEVEAioQAV6ol+yb2S/NrMHM3u5SVmFmT5pZnb8e3eW1v/X/BhvM7I/yU+tjZ2YTzewPZrbezN4xs7/yywu5zSVm9pqZvem3+Va/vGDb3MnMoma2xswe8fcLus1mVm9m68xsrZmt8ssGts3OuSG94J0g/QA4HigC3gRm5LteOWrbAmA+8HaXsn8ElvrbS4F/8Ldn+G0vBqb6f5NovtvQx/ZWA/P97RHA+367CrnNBgz3t+PAq8CZhdzmLm3/BnA38Ii/X9BtBuqBsUeUDWibg9ADL9hL9p1zzwG7jyi+DFjuby8HLu9S/p/OuXbn3EfARry/TWA457Y7597wtw8A6/Gu6C3kNjvnXLO/2/nYeEcBtxnAzGqAS4Cfdyku6DZ3Y0DbHIQAz3TJ/oQ81WUwjHPObQcv8IAqv7yg/g5mNgWYh9cjLeg2+0MJa4EG4EnnXMG3Gbgd+CaQ7lJW6G12wAozW+3fQgQGuM1BeCZmVpfsh0DB/B3MbDhwP/B159x+6/5prwXRZudcCphrZqOA35rZrB4OD3ybzexSoME5t9rMzsvmLRnKAtVm39nOuW1mVgU8aWbv9XBsTtochB542C7Z32lm1QD+usEvL4i/g5nF8cL7LufcA35xQbe5k3NuL/AMcCGF3eazgc+bWT3ekOcFZnYnhd1mnHPb/HUD8Fu8IZEBbXMQAjxsl+w/DCzxt5cAD3Up/6KZFZvZVGAa8Foe6nfMzOtq/wJY75z75y4vFXKbK/2eN2ZWCnwWeI8CbrNz7m+dczXOuSl4/78+7Zz7EgXcZjMrM7MRndvAYuBtBrrN+T5zm+XZ3YvxZix8AHwn3/XJYbt+DWwHEni/yDcCY4CVQJ2/ruhy/Hf8v8EG4KJ81/8Y2nsO3j8T3wLW+svFBd7mOcAav81vA7f45QXb5iPafx6fzEIp2DbjzZJ701/e6cypgW6zLqUXEQmoIAyhiIhIBgpwEZGAUoCLiASUAlxEJKAU4CIiAaUAFxEJKAW4iEhA/X/+kT8jVPfmTQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(losses1, label=\"model1\")\n",
    "plt.plot(losses2, label=\"model2\")\n",
    "plt.ylim([0, 70])\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "banned-honolulu"
   },
   "source": [
    "Let's compare the MSE loss on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "parallel-following",
    "outputId": "1b925d04-6c03-4dd6-ff62-4a2f347fa1aa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE loss for model1:  tensor(0.2814, grad_fn=<MseLossBackward>)\n",
      "MSE loss for model2:  tensor(0.3829, grad_fn=<MseLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "# prediction for model 1\n",
    "model1_pred = model1(x_test)\n",
    "print(\"MSE loss for model1: \", criterion(model1_pred, y_test))\n",
    "# prediction for model 2\n",
    "model2_pred = model2(x_test)\n",
    "print(\"MSE loss for model2: \", criterion(model2_pred, y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wrong-corporation"
   },
   "source": [
    "## Now it is your turn!\n",
    "### Exercises\n",
    "\n",
    "1- Let's get back to model1. This time try to train it with a new optimizer. Try the Adam optimizer (which has shown to be faster than SGD for non-convex functions) and compare the trainig loss curve with SGD. Plot the training loss for the model trained with SGD and Adam optimizer.\n",
    "\n",
    "Note1: Use `torch.optim.Adam(model1.parameters(), lr=...)`\n",
    "\n",
    "Note2: If you are interested, check [this nice post](https://ruder.io/optimizing-gradient-descent/index.html) on differen gradient descent optimization algorithms.\n",
    "\n",
    "2- This time we want to build a new model with a new architecture. Specifically, we want to train a network with 3 hidden layers on the data. You can use the following code to build the architecture. Use the values 500, 1000, 200 for H1, H2, and H3 respectively. Train this new network on the same training data and compare it with the model1 we built above.\n",
    "\n",
    "```\n",
    "class Net_new(nn.Module):\n",
    "    def __init__(self, D_in, H1, H2, H3, D_out):\n",
    "        super(Net_new, self).__init__()\n",
    "\n",
    "        self.linear1 = nn.Linear(D_in, H1)\n",
    "        self.linear2 = nn.Linear(H1, H2)\n",
    "        self.linear3 = nn.Linear(H2, H3)\n",
    "        self.linear4 = nn.Linear(H3, D_out)\n",
    "        self.activation = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        y_pred = self.activation(self.linear1(x))\n",
    "        y_pred = self.activation(self.linear2(y_pred))\n",
    "        y_pred = self.activation(self.linear3(y_pred))\n",
    "        y_pred = self.linear4(y_pred)\n",
    "        return y_pred\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "respiratory-drink"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "name": "Pytorch_regression.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
